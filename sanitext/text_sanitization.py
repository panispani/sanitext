# Test
#     sample_text = "Th—ñs t–µxt c–ænta—ñns homoglyphs and inv—ñsibl–µ characters.‚Äã"
#     ascii_text = "This text contains homoglyphs and invisible characters."  # this is actually ascii


import unicodedata
import re

# Mapping Unicode homoglyphs to standard ASCII equivalents
HOMOGLYPH_MAP = {
    "–∞": "a",
    "–µ": "e",
    "–æ": "o",
    "—Å": "c",
    "—Ä": "p",
    "—Ö": "x",
    "—ñ": "i",
    "‘Å": "d",
    "‚Äô": "'",
    "‚Äò": "'",
    "‚Äú": '"',
    "‚Äù": '"',
    "‚Äû": '"',
    "‚Äê": "-",
    "‚Äì": "-",
    "‚Äî": "-",
    "‚Äâ": " ",
    "‚ÄØ": " ",
    "‚Äã": "",
    "‚Äá": " ",
    "‚ÄÄ": " ",
    "‚ÄÅ": " ",
    "‚†Ä": " ",
    "·†é": " ",
    "ùêÄ": "A",
    "ùêÅ": "B",
    "‚ÑÇ": "C",
    "‚Ñ∞": "E",
    "‚Ñ±": "F",
    "‚Ñù": "R",
    "‚Ñ§": "Z",
    "Ôº°": "A",
    "Ôº¢": "B",
    "Ôº£": "C",
    "Ôº§": "D",
    "Ôº•": "E",
    "Ôºë": "1",
    "Ôºí": "2",
    "Ôºì": "3",
}

# Pattern to detect invisible characters
INVISIBLE_CHARACTERS = re.compile(r"[‚Äã‚Äå‚Äç‚ÄØ‚†Ä·†é‡º¥]")


def detect_unicode_anomalies(text):
    """Detects non-standard Unicode characters in a given text."""
    anomalies = []
    for char in text:
        if char in HOMOGLYPH_MAP or INVISIBLE_CHARACTERS.search(char):
            anomalies.append((char, unicodedata.name(char, "Unknown")))
    return anomalies


def normalize_to_standard(text):
    """Replaces non-standard Unicode characters with their ASCII equivalents."""
    # Replace known homoglyphs
    for uni_char, ascii_char in HOMOGLYPH_MAP.items():
        text = text.replace(uni_char, ascii_char)

    # Remove invisible characters
    text = INVISIBLE_CHARACTERS.sub("", text)

    # Apply Unicode normalization
    return unicodedata.normalize("NFKC", text)
